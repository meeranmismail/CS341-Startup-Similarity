{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "### This notebook achieves the following objectives:\n",
      "\n",
      "    A) IDF-Vector Compute the IDF values for each word present in the corpus \n",
      "    of training samples (which in this case is the set of 3000 labeled companies)\n",
      "\n",
      "    B) Generate the graph. Compute the Jaccard similarity between \n",
      "    companies sharing similar high IDF words, and then populate the \n",
      "    graph where a node is a company and an edge is weighted by the \n",
      "    Jaccard similarity between the two companies (if calculated based on cutoff)\n",
      "\n",
      "    C) Run a simple test of taking two companies, placing all of \n",
      "    their weighted edges in a respective vector, then computing \n",
      "    the dot product between these two edges\n",
      "\n",
      "    Conclusion: We have found that the dot product method is \n",
      "    producing results in which the companies with the highest \n",
      "    dot products do in fact appear very similar. See part C for exact results\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "# A) IDF Vector\n",
      "### To use an IDF vector, you have two options:\n",
      "\n",
      " #### Option 1: Use this code to generate a new IDF vector from words in the training dataset. This option has multiple cells to run\n",
      " \n",
      " #### Option 2: Use this code to read in a previously stored IDF vector. This option has one cell to run\n",
      "The currently implemented option 2 use case reads in the entire 650,000 companies from the raw data file and filters down to 100,000 companies which all have full pitch book descriptions\n",
      "             \n",
      " Note: Run either option 1 or option 2. If both are run, option 2 IDF vector will be used ebcause it will overwrite the variable set by option 1\n",
      " "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "  ----------------------------------------------------------------------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Option 1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import math\n",
      "import re\n",
      "from operator import itemgetter\n",
      "import string\n",
      "import nltk\n",
      "\n",
      "class TfIdf:\n",
      "\n",
      "    \"\"\"Tf-idf class implementing http://en.wikipedia.org/wiki/Tf-idf.\n",
      "  \n",
      "     The library constructs an IDF corpus and stopword list either from\n",
      "     documents specified by the client, or by reading from input files.  It\n",
      "     computes IDF for a specified term based on the corpus, or generates\n",
      "     keywords ordered by tf-idf for a specified document.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, corpus_filename = None, stopword_filename = None,\n",
      "               DEFAULT_IDF = 1.5):\n",
      "        \"\"\"Initialize the idf dictionary.  \n",
      "    \n",
      "        If a corpus file is supplied, reads the idf dictionary from it, in the\n",
      "        format of:\n",
      "        # of total documents\n",
      "        term: # of documents containing the term\n",
      "\n",
      "        If a stopword file is specified, reads the stopword list from it, in\n",
      "        the format of one stopword per line.\n",
      "\n",
      "        The DEFAULT_IDF value is returned when a query term is not found in the\n",
      "        idf corpus.\n",
      "        \"\"\"\n",
      "        self.num_docs = 0\n",
      "        self.term_num_docs = {}     # term : num_docs_containing_term\n",
      "        self.stopwords = []\n",
      "        self.idf_default = DEFAULT_IDF\n",
      "\n",
      "        if corpus_filename:\n",
      "            corpus_file = open(corpus_filename, \"r\")\n",
      "\n",
      "          # Load number of documents.\n",
      "            line = corpus_file.readline()\n",
      "            self.num_docs = int(line.strip())\n",
      "\n",
      "          # Reads \"term:frequency\" from each subsequent line in the file.\n",
      "            for line in corpus_file:\n",
      "                tokens = line.split(\":\")\n",
      "                term = tokens[0].strip()\n",
      "                frequency = int(tokens[1].strip())\n",
      "                self.term_num_docs[term] = frequency\n",
      "\n",
      "        if stopword_filename:\n",
      "            stopword_file = open(stopword_filename, \"r\")\n",
      "            self.stopwords = [line.strip() for line in stopword_file]\n",
      "\n",
      "    def get_tokens(self, doc):\n",
      "        \"\"\"Break a string into tokens, preserving URL tags as an entire token.\n",
      "\n",
      "        This implementation does not preserve case.  \n",
      "        Clients may wish to override this behavior with their own tokenization.\n",
      "        \"\"\"\n",
      "        # Attempt 1 - Faster results (this one is faster than uncommented solution, but doesn't get rid of stop words)\n",
      "        #str_list = [word.lower().translate(str.maketrans(' ', ' ', string.punctuation)) for word in re.split('\\s|\\.|-|,',str(doc))]\n",
      "        \n",
      "        punctuation = '[^\\w\\s]'\n",
      "        doc = pd.Series(doc)\n",
      "        txt = doc.str.lower().str.replace(punctuation, ' ').str.cat(sep=' ')\n",
      "        stopwords = set(nltk.corpus.stopwords.words('english'))\n",
      "        words = nltk.tokenize.word_tokenize(txt)\n",
      "        return set(words) - stopwords\n",
      "\n",
      "        \n",
      "    def add_input_document(self, input):\n",
      "        \"\"\"Add terms in the specified document to the idf dictionary.\"\"\"\n",
      "        self.num_docs += 1\n",
      "        words = set(self.get_tokens(input))\n",
      "        for word in words:\n",
      "            if word in self.term_num_docs:\n",
      "                self.term_num_docs[word] += 1\n",
      "            else:\n",
      "                self.term_num_docs[word] = 1\n",
      "\n",
      "    def save_corpus_to_file(self, idf_filename, stopword_filename,\n",
      "                          STOPWORD_PERCENTAGE_THRESHOLD = 0.01):\n",
      "        \"\"\"Save the idf dictionary and stopword list to the specified file.\"\"\"\n",
      "        output_file = open(idf_filename, \"w\")\n",
      "\n",
      "        output_file.write(str(self.num_docs) + \"\\n\")\n",
      "        for term, num_docs in self.term_num_docs.items():\n",
      "            output_file.write(term + \": \" + str(num_docs) + \"\\n\")\n",
      "\n",
      "        sorted_terms = sorted(self.term_num_docs.items(), key=itemgetter(1),\n",
      "                          reverse=True)\n",
      "        stopword_file = open(stopword_filename, \"w\")\n",
      "        for term, num_docs in sorted_terms:\n",
      "            if num_docs < STOPWORD_PERCENTAGE_THRESHOLD * self.num_docs:\n",
      "                break\n",
      "\n",
      "            stopword_file.write(term + \"\\n\")\n",
      "\n",
      "    def get_num_docs(self):\n",
      "        \"\"\"Return the total number of documents in the IDF corpus.\"\"\"\n",
      "        return self.num_docs\n",
      "\n",
      "    def get_idf(self, term):\n",
      "        \"\"\"Retrieve the IDF for the specified term. \n",
      "    \n",
      "        This is computed by taking the logarithm of ( \n",
      "        (number of documents in corpus) divided by (number of documents\n",
      "        containing this term) ).\n",
      "        \"\"\"\n",
      "        if term in self.stopwords:\n",
      "            return 0\n",
      "\n",
      "        if not term in self.term_num_docs:\n",
      "            return self.idf_default\n",
      "\n",
      "        return math.log(float(1 + self.get_num_docs()) / (1 + self.term_num_docs[term]))"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Now read in the full raw dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "#################### Full Data #########################\n",
      "training_categories_df = pd.read_csv(\"/users/Meeranster/CS341/data/raw_data_fixed.csv\",  encoding = \"ISO-8859-1\", usecols=['domain'\\\n",
      ", 'tx_industry', 'cb_category', 'tx_category', 'cb_desc', 'pb_desc', 'pb_category'])\n",
      "\n",
      "#mydoclist = training_categories_df.ix[0:,'pb_desc'].values"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Filter out companies that do not have a pitch book provided description"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Filter out all companies that don't have a pitch book provided description\n",
      "subset_df_pb_desc = training_categories_df.ix[training_categories_df['pb_desc'].notnull()]\n",
      "\n",
      "\n",
      "# Now print out some info\n",
      "len_of_df = subset_df_pb_desc.shape[0]\n",
      "print(\"There are {} companies that have a full pitch book provided description\".format(len_of_df))\n"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "There are 166406 companies that have a full pitch book provided description\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Uncomment below line if you need to write the filtered companies to a csv\n",
      "#subset_df_pb_desc.to_csv(\"../../data/100000_companies_with_description.csv\")"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Cut this down to 100,000 companies using the head function\n",
      "subset_df_pb_desc = subset_df_pb_desc.head(10000)\n",
      "company_list = subset_df_pb_desc\n",
      "print(\"Size of final dataframe to use for building the graph: {}\".format(subset_df_pb_desc.shape[0]))\n",
      "#subset_df_pb_desc"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Size of final dataframe to use for building the graph: 10000\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Adding missing companies from the pairs dataset to the graph."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, filter all the rated pairs for those with both PitchBook descriptions present."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rated_pairs =  pd.read_csv(\"/users/Meeranster/CS341/data/company_pairs_training.csv\",  encoding = \"ISO-8859-1\")\n",
      "training_pairs = rated_pairs.ix[rated_pairs['pb_desc1'].notnull()]\n",
      "training_pairs = training_pairs.ix[rated_pairs['pb_desc2'].notnull()]\n",
      "training_pairs.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "(1110, 17)"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, go through the list of companies in these pairs and see if they are in our initial dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(company_list.iloc[0])\n",
      "print(training_pairs.iloc[23])\n",
      "company_list.iloc[0][['domain', 'tx_industry','cb_category']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "domain                                                  0-in.com\n",
        "tx_industry                                           Technology\n",
        "cb_category                                                  NaN\n",
        "tx_category                                       Semiconductors\n",
        "cb_desc                                                      NaN\n",
        "pb_desc        Operator of an assertion-based verification co...\n",
        "pb_category                         Automation/Workflow Software\n",
        "Name: 2, dtype: object\n",
        "domain1                                               accuwatt.fr\n",
        "domain2                                                acdbio.com\n",
        "rating                                                          3\n",
        "tx_industry1                                                  NaN\n",
        "cb_category1    Manufacturer of lithium batteries. The company...\n",
        "tx_category1                                       Energy Storage\n",
        "pb_desc1                                 CleanTech, Manufacturing\n",
        "cb_desc1                                                      NaN\n",
        "pb_industry1                                                  NaN\n",
        "pb_category1                                   Alternative Energy\n",
        "tx_industry2                                        Life Sciences\n",
        "cb_category2    Developer of cell and tissue based diagnostic ...\n",
        "tx_category2                                        Biotechnology\n",
        "pb_desc2                                  Life Sciences, Oncology\n",
        "cb_desc2        Advanced Cell Diagnostics is a molecular patho...\n",
        "pb_industry2             biotechnology|health diagnostics|medical\n",
        "pb_category2                            Biotech & Pharmaceuticals\n",
        "Name: 56, dtype: object\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "domain           0-in.com\n",
        "tx_industry    Technology\n",
        "cb_category           NaN\n",
        "Name: 2, dtype: object"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "company_set = set(company_list['domain'].values)\n",
      "#domains 1 and 2 are indexes 0 and 1 in the panda series\n",
      "n_pairs = training_pairs.shape[0]\n",
      "new_companies = []\n",
      "for i in range(n_pairs):\n",
      "    company1 = training_pairs.iloc[i]['domain1']\n",
      "    company2 = training_pairs.iloc[i]['domain2']\n",
      "    if company1 not in company_set:\n",
      "        new_companies.append(training_pairs.iloc[i][['domain1', 'tx_industry1', \n",
      "                                                     'cb_category1', \n",
      "                                                     'tx_category1', 'cb_desc1',\n",
      "                                                     'pb_desc1', 'pb_category1']])\n",
      "        company_set.add(company1)\n",
      "    if company2 not in company_set:\n",
      "        new_companies.append(training_pairs.iloc[i][['domain2', 'tx_industry2', \n",
      "                                                     'cb_category2', \n",
      "                                                     'tx_category2', 'cb_desc2',\n",
      "                                                     'pb_desc2', 'pb_category2']])\n",
      "        company_set.add(company2)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Stuck Here!!!!!!!!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.DataFrame(new_companies)\n",
      "df = df.fillna('')\n",
      "df.reset_index(inplace = True)\n",
      "df['domain'] = df[['domain1','domain2']].apply(lambda x : '{}{}'.format(x[0],x[1]), axis=1)\n",
      "df['tx_industry'] = df[['tx_industry1', 'tx_industry2']].apply(lambda x : '{}{}'.format(x[0],x[1]), axis=1)\n",
      "df['tx_category'] = df[['tx_category1','tx_category2']].apply(lambda x : '{}{}'.format(x[0],x[1]), axis=1)\n",
      "# df['cb_desc'] = df[['cb_desc1','cb_desc2']].apply(lambda x : '{}{}'.format(x[0],x[1]), axis=1)\n",
      "# df['pb_desc'] = df[['pb_desc1','pb_desc2']].apply(lambda x : '{}{}'.format(x[0],x[1]), axis=1)\n",
      "df['pb_category'] = df[['pb_category1','pb_category2']].apply(lambda x : '{}{}'.format(x[0],x[1]), axis=1)\n",
      "df['pb_category'][2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "UnicodeEncodeError",
       "evalue": "'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-128-7c655ef109f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tx_category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tx_category1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tx_category2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'{}{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# df['cb_desc'] = df[['cb_desc1','cb_desc2']].apply(lambda x : '{}{}'.format(x[0],x[1]), axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pb_desc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pb_desc1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pb_desc2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'{}{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pb_category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pb_category1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pb_category2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'{}{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pb_category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Meeranster/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4150\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4151\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4152\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4154\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Meeranster/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4246\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4247\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4248\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4249\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4250\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-128-7c655ef109f0>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tx_category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tx_category1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tx_category2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'{}{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# df['cb_desc'] = df[['cb_desc1','cb_desc2']].apply(lambda x : '{}{}'.format(x[0],x[1]), axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pb_desc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pb_desc1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pb_desc2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'{}{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pb_category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pb_category1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pb_category2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'{}{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pb_category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)"
       ]
      }
     ],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mydoclist = company_list['pb_desc'].values\n",
      "print(len(mydoclist))\n"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10000\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "This code computes the actual IDF vector and can take a couple minutes to run with 100,000 samples"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "idfcalc = TfIdf()\n",
      "for entry in mydoclist:\n",
      "    idfcalc.add_input_document(entry)\n",
      "#print(idfcalc.term_num_docs)\n",
      "\n",
      "idf_vec = []\n",
      "term_vec = []\n",
      "for term in idfcalc.term_num_docs:\n",
      "    idf = idfcalc.get_idf(term)\n",
      "    idf_vec.append(idf)\n",
      "    term_vec.append(term)"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Convert the IDF vector a pandas Series and sort by IDF value (in descending order)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "idf_vector = pd.Series(idf_vec, index=term_vec)\n",
      "\n",
      "sorted_idf_vector = idf_vector.sort_values(ascending=False)\n",
      "idf_vector = sorted_idf_vector\n",
      "print(idf_vector)"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "alivamab        8.517293\n",
        "streamers       8.517293\n",
        "gangs           8.517293\n",
        "313             8.517293\n",
        "dehydration     8.517293\n",
        "adopted         8.517293\n",
        "suggested       8.517293\n",
        "graving         8.517293\n",
        "doctoral        8.517293\n",
        "antifungal      8.517293\n",
        "ballast         8.517293\n",
        "arabica         8.517293\n",
        "shingles        8.517293\n",
        "rhode           8.517293\n",
        "heavier         8.517293\n",
        "ingestible      8.517293\n",
        "grip            8.517293\n",
        "alfalfa         8.517293\n",
        "baofeng         8.517293\n",
        "factfinder      8.517293\n",
        "presentable     8.517293\n",
        "mos             8.517293\n",
        "admitting       8.517293\n",
        "bow             8.517293\n",
        "forge           8.517293\n",
        "contributors    8.517293\n",
        "calpian         8.517293\n",
        "moc             8.517293\n",
        "equips          8.517293\n",
        "savorous        8.517293\n",
        "                  ...   \n",
        "systems         2.724280\n",
        "business        2.718201\n",
        "designed        2.669410\n",
        "development     2.666529\n",
        "allows          2.656507\n",
        "service         2.653662\n",
        "enabling        2.649410\n",
        "helps           2.625649\n",
        "enables         2.474660\n",
        "applications    2.448868\n",
        "also            2.432794\n",
        "operator        2.377409\n",
        "data            2.322888\n",
        "application     2.267318\n",
        "users           2.228506\n",
        "mobile          2.089188\n",
        "management      2.062095\n",
        "technology      2.008524\n",
        "develops        1.966927\n",
        "products        1.957678\n",
        "based           1.869605\n",
        "software        1.826451\n",
        "online          1.614550\n",
        "provides        1.319858\n",
        "offers          1.304999\n",
        "services        1.303893\n",
        "platform        1.171606\n",
        "developer       1.159737\n",
        "provider        0.678162\n",
        "company         0.019589\n",
        "dtype: float64\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Uncomment the below line to save the IDF vector to a file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This code saves the IDF vector to a file\n",
      "# idf_vector.to_csv(\"../../data/100000_companies_with_description_idf_vector.csv\")"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "End Option 1"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Option 2 (skip this if option 1 was utilized, else proceed to read an IDF vector from a csv file)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# Read in the IDF vector\n",
      "idf_vector = pd.read_csv(\"../../data/100000_companies_with_description_idf_vector.csv\" ,header=None, \\\n",
      "                         names=['IDF'], index_col=0, encoding = \"ISO-8859-1\")\n",
      "idf_vector"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [
      {
       "html": [
        "<div>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>IDF</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>dioxin</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>spiegelmers</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>nanopositioning</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>schlumberger</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>handelsblad</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>nrc</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>gassification</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>pyro</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>tme</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ntag</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>latticed</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ntp</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>neurotherapeutics</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>trickster</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>pangya</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>omnigen</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>nutricosmetics</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>acreages</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>protide</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>characteristic</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>epicheck</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>careful</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>chemetics</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>photosensitive</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>suscription</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>nanopositioners</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>cauterization</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>miltiple</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>colli</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>quadrantanopia</th>\n",
        "      <td>10.819788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>allows</th>\n",
        "      <td>2.749195</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>information</th>\n",
        "      <td>2.744828</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>helps</th>\n",
        "      <td>2.741410</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>systems</th>\n",
        "      <td>2.741100</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>web</th>\n",
        "      <td>2.703819</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>service</th>\n",
        "      <td>2.700687</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>applications</th>\n",
        "      <td>2.694601</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>business</th>\n",
        "      <td>2.694157</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>manufacturer</th>\n",
        "      <td>2.558908</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>enables</th>\n",
        "      <td>2.548496</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>data</th>\n",
        "      <td>2.471961</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>also</th>\n",
        "      <td>2.324841</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>application</th>\n",
        "      <td>2.321370</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>operator</th>\n",
        "      <td>2.307407</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>technology</th>\n",
        "      <td>2.242912</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mobile</th>\n",
        "      <td>2.222214</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>users</th>\n",
        "      <td>2.193920</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>develops</th>\n",
        "      <td>2.162138</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>management</th>\n",
        "      <td>2.041616</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>based</th>\n",
        "      <td>2.014788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>software</th>\n",
        "      <td>1.951868</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>products</th>\n",
        "      <td>1.943872</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>online</th>\n",
        "      <td>1.682341</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>developer</th>\n",
        "      <td>1.370470</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>provides</th>\n",
        "      <td>1.294455</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>platform</th>\n",
        "      <td>1.288343</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>offers</th>\n",
        "      <td>1.277881</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>services</th>\n",
        "      <td>1.135172</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>provider</th>\n",
        "      <td>0.647687</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>company</th>\n",
        "      <td>0.026754</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>49813 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "                         IDF\n",
        "dioxin             10.819788\n",
        "spiegelmers        10.819788\n",
        "nanopositioning    10.819788\n",
        "schlumberger       10.819788\n",
        "handelsblad        10.819788\n",
        "nrc                10.819788\n",
        "gassification      10.819788\n",
        "pyro               10.819788\n",
        "tme                10.819788\n",
        "ntag               10.819788\n",
        "latticed           10.819788\n",
        "ntp                10.819788\n",
        "neurotherapeutics  10.819788\n",
        "trickster          10.819788\n",
        "pangya             10.819788\n",
        "omnigen            10.819788\n",
        "nutricosmetics     10.819788\n",
        "acreages           10.819788\n",
        "protide            10.819788\n",
        "characteristic     10.819788\n",
        "epicheck           10.819788\n",
        "careful            10.819788\n",
        "chemetics          10.819788\n",
        "photosensitive     10.819788\n",
        "suscription        10.819788\n",
        "nanopositioners    10.819788\n",
        "cauterization      10.819788\n",
        "miltiple           10.819788\n",
        "colli              10.819788\n",
        "quadrantanopia     10.819788\n",
        "...                      ...\n",
        "allows              2.749195\n",
        "information         2.744828\n",
        "helps               2.741410\n",
        "systems             2.741100\n",
        "web                 2.703819\n",
        "service             2.700687\n",
        "applications        2.694601\n",
        "business            2.694157\n",
        "manufacturer        2.558908\n",
        "enables             2.548496\n",
        "data                2.471961\n",
        "also                2.324841\n",
        "application         2.321370\n",
        "operator            2.307407\n",
        "technology          2.242912\n",
        "mobile              2.222214\n",
        "users               2.193920\n",
        "develops            2.162138\n",
        "management          2.041616\n",
        "based               2.014788\n",
        "software            1.951868\n",
        "products            1.943872\n",
        "online              1.682341\n",
        "developer           1.370470\n",
        "provides            1.294455\n",
        "platform            1.288343\n",
        "offers              1.277881\n",
        "services            1.135172\n",
        "provider            0.647687\n",
        "company             0.026754\n",
        "\n",
        "[49813 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "End Option 2"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Run the next code no matter which option was used"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Get the idf values in a column vector\n",
      "idf_values = list(idf_vector.values)\n",
      "\n",
      "# Get the words in a column vector. The initial order mathes the \n",
      "# values in the idf_values_array\n",
      "idf_words = list(idf_vector.index.values)\n",
      "# Perform a reshape on the words array to get it in a better format\n",
      "\n",
      "idf_set = set(idf_words)\n",
      "idf_map = dict(zip(idf_words, idf_values))\n"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "B) Creating the Graph"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "The next step will be to create an adjacency matrix to store all these values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "#Uncomment if you did Option 2 instead of Option 1\n",
      "# company_list = pd.read_csv('../../data/100000_companies_with_description.csv',  encoding = \"ISO-8859-1\", \\\n",
      "#                            usecols=['domain', 'tx_industry', 'cb_category', 'tx_category', 'cb_desc',\\\n",
      "#                                     'pb_desc', 'pb_category'])\n",
      "\n",
      "company_list.head()"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>domain</th>\n",
        "      <th>tx_industry</th>\n",
        "      <th>cb_category</th>\n",
        "      <th>tx_category</th>\n",
        "      <th>cb_desc</th>\n",
        "      <th>pb_desc</th>\n",
        "      <th>pb_category</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>0-in.com</td>\n",
        "      <td>Technology</td>\n",
        "      <td>NaN</td>\n",
        "      <td>Semiconductors</td>\n",
        "      <td>NaN</td>\n",
        "      <td>Operator of an assertion-based verification co...</td>\n",
        "      <td>Automation/Workflow Software</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td>012.net</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>Telecom Operators</td>\n",
        "      <td>NaN</td>\n",
        "      <td>Provider of internet and international telepho...</td>\n",
        "      <td>Internet Service Providers</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td>1-2-3.tv</td>\n",
        "      <td>Consumer</td>\n",
        "      <td>auctions|e-commerce|internet|shopping</td>\n",
        "      <td>Online Retail</td>\n",
        "      <td>1-2-3.tv is a multichannel auction house with ...</td>\n",
        "      <td>Operator of television broadcasting station th...</td>\n",
        "      <td>Broadcasting, Radio and Television</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td>1-2-social.de</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>Outsourcing</td>\n",
        "      <td>NaN</td>\n",
        "      <td>Provider of social media marketing services. T...</td>\n",
        "      <td>Social Content</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>47</th>\n",
        "      <td>10-4.com</td>\n",
        "      <td>Consumer</td>\n",
        "      <td>marketplace|mobile|software|transportation</td>\n",
        "      <td>Logistics Tech</td>\n",
        "      <td>10-4 is redefining the future of transportatio...</td>\n",
        "      <td>Provider of supply chain visibility technology...</td>\n",
        "      <td>Other Commercial Services</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "           domain tx_industry                                 cb_category  \\\n",
        "2        0-in.com  Technology                                         NaN   \n",
        "16        012.net         NaN                                         NaN   \n",
        "34       1-2-3.tv    Consumer       auctions|e-commerce|internet|shopping   \n",
        "35  1-2-social.de         NaN                                         NaN   \n",
        "47       10-4.com    Consumer  marketplace|mobile|software|transportation   \n",
        "\n",
        "          tx_category                                            cb_desc  \\\n",
        "2      Semiconductors                                                NaN   \n",
        "16  Telecom Operators                                                NaN   \n",
        "34      Online Retail  1-2-3.tv is a multichannel auction house with ...   \n",
        "35        Outsourcing                                                NaN   \n",
        "47     Logistics Tech  10-4 is redefining the future of transportatio...   \n",
        "\n",
        "                                              pb_desc  \\\n",
        "2   Operator of an assertion-based verification co...   \n",
        "16  Provider of internet and international telepho...   \n",
        "34  Operator of television broadcasting station th...   \n",
        "35  Provider of social media marketing services. T...   \n",
        "47  Provider of supply chain visibility technology...   \n",
        "\n",
        "                           pb_category  \n",
        "2         Automation/Workflow Software  \n",
        "16          Internet Service Providers  \n",
        "34  Broadcasting, Radio and Television  \n",
        "35                      Social Content  \n",
        "47           Other Commercial Services  "
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "============ Stuck here, need to use a sparse matrix"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "n_companies = company_list.shape[0]\n",
      "company_graph = np.empty((n_companies,n_companies))\n",
      "company_graph[:] = 0\n",
      "company_graph"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       ..., \n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Next, we'll go through each word and see which companies have that word. \n",
      "We'll go through the top 1000 idf words, find the companies with those words, \n",
      "and then compare them to create the edge weight in the graph.  \n",
      "First, the following function creates a set of words out of the description"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import string\n",
      "import nltk\n",
      "nltk.download('punkt')\n",
      "\n",
      "#Gets the words out of the labeled descriptions\n",
      "def get_words(df):\n",
      "    punctuation = '[^\\w\\s]'\n",
      "    txt = df.str.lower().str.replace(punctuation, ' ').str.cat(sep=' ')\n",
      "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
      "    words = nltk.tokenize.word_tokenize(txt)\n",
      "    return set(words) - stopwords\n",
      "\n"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[nltk_data] Downloading package punkt to\n",
        "[nltk_data]     /Users/Meeranster/nltk_data...\n",
        "[nltk_data]   Package punkt is already up-to-date!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Now, we create a company_words_list, i.e. each company is associated with a set of words."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "company_words_list = [set()]*len(company_list)\n",
      "for i in range(len(company_list)):\n",
      "    start_index = 5\n",
      "    end_index = 6 #only for pb_desc\n",
      "    company_words = get_words(company_list.iloc[i,start_index:end_index])\n",
      "    company_words_list[i] = company_words\n"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "company_words_list[4325]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "{u'blood',\n",
        " u'cardiovascular',\n",
        " u'care',\n",
        " u'clots',\n",
        " u'company',\n",
        " u'developer',\n",
        " u'devices',\n",
        " u'fluids',\n",
        " u'general',\n",
        " u'givers',\n",
        " u'help',\n",
        " u'irrigation',\n",
        " u'lavage',\n",
        " u'management',\n",
        " u'medical',\n",
        " u'nurses',\n",
        " u'oncology',\n",
        " u'pain',\n",
        " u'pathology',\n",
        " u'patient',\n",
        " u'physicians',\n",
        " u'procedures',\n",
        " u'provides',\n",
        " u'remove',\n",
        " u'spine',\n",
        " u'technicians',\n",
        " u'thrombus',\n",
        " u'tissue',\n",
        " u'use',\n",
        " u'used',\n",
        " u'wound'}"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "This function goes through the list of companies and sees if a \n",
      "given word is in the description for each of the companies, \n",
      "returning a set of company indices with that word."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#given a target word and a pandas data frame of companies, \n",
      "# returns a list of companies whose descriptions contain the target word\n",
      "def get_companies(target_word, company_words_list):\n",
      "    candidate_set = set()\n",
      "    for i in range(len(company_words_list)):\n",
      "        company_description = company_words_list[i]\n",
      "        if target_word in company_description:\n",
      "            candidate_set.add(i)\n",
      "    return list(candidate_set)\n",
      "        "
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "This function takes a candidate pair, and computes their weighted \n",
      "similarity by finding Jaccard similarity and then weighing it by the idf of the words."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_similarity(company_index_1, company_index_2, company_words_list, idf_set, idf_map):\n",
      "    company_1 = company_words_list[company_index_1]\n",
      "    company_2 = company_words_list[company_index_2]\n",
      "    intersection = company_1 & company_2\n",
      "    union = company_1 | company_2\n",
      "    if len(union) == 0:\n",
      "        return 0\n",
      "    intersection_score = 0.0\n",
      "    union_score = 0.0\n",
      "    for word in union:\n",
      "        if word in idf_set:\n",
      "            word_score = idf_map[word]\n",
      "            union_score += word_score\n",
      "            if word in intersection:\n",
      "                intersection_score += word_score\n",
      "                \n",
      "    return intersection_score/union_score\n",
      "        "
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Now, we go through and construct the 10000x10000 adjacency matrix."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size(company_graph[company_graph > 0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_updated_elements = 0\n",
      "n_companies = len(company_list)\n",
      "cutoff = 0.1\n",
      "for i in range(n_companies):\n",
      "    for k in range((i+1), n_companies):\n",
      "        edge_weight = get_similarity(i, k, company_words_list, idf_set, idf_map)\n",
      "        if edge_weight >= cutoff:\n",
      "            company_graph[i][k] = edge_weight\n",
      "            company_graph[k][i] = edge_weight\n",
      "        \n",
      "#removing -1's and ensuring 1's along the diagonal\n",
      "\n",
      "np.fill_diagonal(company_graph, 1)\n",
      "company_graph[company_graph < 0] = 0"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "float(size(company_graph[company_graph > 0]) - n_companies)/(n_companies*n_companies - n_companies)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "0.0025212721272127214"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Here I test different cutoffs for similarity scores to count as edges."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cutoff_sparsity = np.zeros(20)\n",
      "#cutoff_sparsity[i] gives the sparsity of the graph if similarity threshold is (i+1)*0.01\n",
      "n_possible_edges = float(company_graph.size - n_companies)\n",
      "for i in range(20):\n",
      "    cutoff_sparsity[i] = \\\n",
      "    (company_graph[company_graph > (i+1)*0.01].size - n_companies)/n_possible_edges\n",
      "print(cutoff_sparsity)"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  2.96565522e-03   2.96565522e-03   2.96565522e-03   2.96565522e-03\n",
        "   2.96565522e-03   2.96565522e-03   2.96565522e-03   2.96565522e-03\n",
        "   2.96565522e-03   2.96565522e-03   1.90018895e-03   1.23107703e-03\n",
        "   8.17161276e-04   5.47960431e-04   3.82127376e-04   2.66310993e-04\n",
        "   1.89841058e-04   1.33822385e-04   9.80326776e-05   7.44692675e-05]\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "C) Dot Product Heuristic"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Now I'm going to perform a very simple heuristic to see how \n",
      "well the dot products predict similarity by seeing how they \n",
      "function on the company pairs with the highest textual similarity scores."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mask = ~np.eye(company_graph.shape[0], dtype = bool)\n",
      "extremes = np.where((mask) & (company_graph > 0.3))"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(extremes[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "642"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dot_products = np.zeros(len(extremes[0]))\n",
      "for i in range(len(dot_products)):\n",
      "    company_1 = extremes[0][i]\n",
      "    company_2 = extremes[1][i]\n",
      "    dot_products[i] = company_graph[company_1].dot(company_graph[company_2])\n",
      "dot_products"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "array([ 1.04921071,  0.86286851,  1.50356502,  1.26225016,  1.24569544,\n",
        "        2.06417015,  1.48271978,  1.44437895,  3.66821923,  1.90527091,\n",
        "        2.63157633,  2.63633721,  2.0339037 ,  1.12844968,  2.68670666,\n",
        "        2.54529777,  1.07664772,  2.05221642,  0.84247275,  3.40632537,\n",
        "        4.33721455,  0.76391133,  1.87167783,  2.27022281,  2.77332165,\n",
        "        2.4631096 ,  1.19709671,  1.57058234,  2.04647176,  1.11859285,\n",
        "        2.71742486,  1.01650265,  3.52593124,  3.33163074,  2.7162154 ,\n",
        "        1.50356502,  2.13825894,  1.32418237,  3.23634405,  1.59730997,\n",
        "        3.66821923,  3.74756183,  1.94907455,  3.52837589,  3.04082508,\n",
        "        2.6147605 ,  3.05770206,  2.38072202,  1.69085693,  1.95596325,\n",
        "        2.37572957,  1.59730997,  2.11408221,  1.65422264,  2.62360487,\n",
        "        2.41006622,  3.2985709 ,  1.84309905,  1.69441414,  1.8330207 ,\n",
        "        1.01650265,  1.65178764,  2.06417015,  2.41006622,  1.03840912,\n",
        "        1.57574544,  1.65178764,  1.45326494,  1.42628837,  1.40806249,\n",
        "        1.75692031,  1.7300655 ,  0.99836937,  2.11408221,  1.46380926,\n",
        "        3.32648561,  1.26225016,  2.13825894,  2.36115892,  1.50089941,\n",
        "        1.52399221,  1.36448518,  1.43680718,  1.00871263,  1.26297949,\n",
        "        1.84818291,  3.96476353,  4.14893538,  3.90019255,  3.04285397,\n",
        "        3.5286386 ,  2.31090715,  2.4944051 ,  1.99158515,  1.48271978,\n",
        "        1.43501656,  1.13071211,  0.99994457,  3.26090012,  1.7747908 ,\n",
        "        1.05739855,  2.04732067,  1.63167963,  1.50790384,  1.50790384,\n",
        "        1.84818291,  3.96476353,  2.64964403,  2.22541396,  3.26090012,\n",
        "        1.69441414,  1.92135844,  1.52728289,  3.40632537,  1.95596325,\n",
        "        2.57454519,  4.53723057,  2.86483028,  1.15747102,  2.57454519,\n",
        "        1.171918  ,  0.98420274,  1.18082716,  1.20680249,  4.33721455,\n",
        "        3.2985709 ,  3.5286386 ,  4.53723057,  4.26598704,  3.17477504,\n",
        "        3.91569027,  1.6046935 ,  2.17359583,  1.00871263,  1.26297949,\n",
        "        1.61139466,  1.23212144,  1.88003652,  2.59750815,  1.71384365,\n",
        "        1.61340265,  1.82084051,  1.78120139,  1.78145892,  0.9026089 ,\n",
        "        1.8330207 ,  1.0569627 ,  3.52593124,  2.37572957,  3.88159618,\n",
        "        3.47643648,  1.13491659,  1.46380926,  0.9969032 ,  1.07590754,\n",
        "        2.08757528,  1.31313249,  1.29389578,  1.26407364,  0.88124374,\n",
        "        0.95343643,  0.99836937,  0.71972944,  1.43536638,  3.04082508,\n",
        "        2.38072202,  1.63167963,  0.80963022,  1.0569627 ,  1.03917243,\n",
        "        0.91319443,  2.33664747,  2.29589873,  0.91319443,  2.21563771,\n",
        "        0.70807744,  1.13071211,  1.31313249,  1.23142214,  3.45760923,\n",
        "        4.49258322,  4.49258322,  4.49258322,  4.49258322,  2.3025303 ,\n",
        "        0.9969032 ,  1.20097894,  1.50089941,  1.19103087,  1.67141513,\n",
        "        1.53558308,  3.01796218,  1.98702173,  2.04629334,  1.10729494,\n",
        "        0.68043347,  4.14893538,  1.11859285,  4.04780783,  2.47903467,\n",
        "        0.73662175,  0.76798663,  0.91987539,  2.6147605 ,  1.80478228,\n",
        "        1.12844968,  1.85072782,  2.0339037 ,  1.07590754,  0.70807744,\n",
        "        0.71095083,  0.71095083,  1.7844639 ,  2.19778462,  0.95432045,\n",
        "        2.04732067,  2.19778462,  1.87167783,  2.27968526,  0.83415742,\n",
        "        2.10776645,  2.16128144,  1.76664468,  2.10842754,  3.18614952,\n",
        "        3.00288808,  1.97992476,  0.80963022,  0.87879513,  2.17144502,\n",
        "        1.76664468,  2.10857152,  1.96177071,  1.90527091,  2.41882443,\n",
        "        1.21739841,  1.57318633,  1.16498645,  1.7300655 ,  2.10853292,\n",
        "        1.89224046,  0.87879513,  2.68670666,  2.86483028,  4.26598704,\n",
        "        1.57058234,  1.65422264,  1.2936678 ,  1.19709671,  1.171918  ,\n",
        "        1.05452613,  1.88003652,  1.08168384,  1.23212144,  0.84247275,\n",
        "        1.40987572,  1.7844639 ,  0.97878831,  1.4325953 ,  2.10857152,\n",
        "        0.84986015,  1.03840912,  0.93219534,  0.97878831,  2.08757528,\n",
        "        2.84416906,  3.06547865,  2.43020874,  2.28324849,  2.8664349 ,\n",
        "        3.90019255,  2.64964403,  2.37483864,  2.46178387,  0.94026302,\n",
        "        1.98702173,  3.45760923,  4.08838779,  4.08838779,  4.08838779,\n",
        "        4.08838779,  2.04785877,  0.83190123,  2.54529777,  2.92597609,\n",
        "        3.40336261,  3.4578504 ,  1.84315085,  1.71606091,  1.84315085,\n",
        "        1.45568776,  2.79505603,  2.09405   ,  1.75965809,  2.39102038,\n",
        "        2.0621636 ,  2.32163348,  1.14248359,  2.4850591 ,  1.45568776,\n",
        "        2.32895012,  2.71742486,  3.74756183,  3.52837589,  2.36115892,\n",
        "        3.28330085,  2.91354052,  2.71998755,  3.64212902,  1.96177071,\n",
        "        2.18803368,  2.63157633,  2.19146441,  4.49258322,  4.08838779,\n",
        "        5.29396284,  5.29396284,  5.29396284,  2.6485885 ,  3.23634405,\n",
        "        1.20098453,  0.95703102,  1.5076211 ,  1.57318633,  1.5076211 ,\n",
        "        1.51164712,  0.86286851,  1.08706622,  0.89620476,  3.28330085,\n",
        "        1.70572458,  1.70880978,  3.32648561,  3.88159618,  1.84309905,\n",
        "        1.16498645,  0.75964705,  1.04921071,  1.7747908 ,  1.13491659,\n",
        "        1.76868263,  1.41795633,  0.93219534,  1.05739855,  0.98420274,\n",
        "        1.45326494,  1.51164712,  0.95703102,  1.58072128,  1.76868263,\n",
        "        1.86985459,  2.62360487,  0.95914641,  2.10853292,  1.92103291,\n",
        "        2.51644768,  2.28873936,  1.20680249,  2.27022281,  2.33664747,\n",
        "        2.84416906,  2.73910453,  2.54257297,  2.5022368 ,  2.75416624,\n",
        "        0.76391133,  1.19103087,  2.77332165,  2.47903467,  3.06547865,\n",
        "        2.73910453,  2.35818567,  2.8288939 ,  1.31671089,  1.97899655,\n",
        "        3.33163074,  3.47643648,  1.6046935 ,  2.7162154 ,  1.75692031,\n",
        "        1.99158515,  2.46178387,  3.27149407,  1.60682258,  0.8401917 ,\n",
        "        0.95672809,  1.19460428,  0.72319834,  1.20098453,  2.91354052,\n",
        "        1.08028477,  1.05452613,  0.75707424,  0.68043347,  1.64359209,\n",
        "        0.75707424,  1.07683914,  1.27139861,  1.79533302,  1.86206295,\n",
        "        1.92135844,  1.22563142,  1.47419595,  1.31671089,  0.84704054,\n",
        "        1.15747102,  1.22563142,  2.16128144,  2.17359583,  3.01796218,\n",
        "        2.10776645,  1.58072128,  1.97899655,  2.46725197,  0.9026089 ,\n",
        "        1.20097894,  1.4325953 ,  1.79533302,  1.86985459,  1.41795633,\n",
        "        0.70862809,  2.31090715,  2.20098912,  0.94026302,  1.512067  ,\n",
        "        2.71998755,  1.21739841,  2.17144502,  2.11188169,  1.8312895 ,\n",
        "        1.24569544,  1.32418237,  1.40806249,  2.43020874,  2.54257297,\n",
        "        2.35818567,  2.49791941,  3.17477504,  0.89620476,  0.90102206,\n",
        "        0.90102206,  1.24455827,  4.49258322,  4.08838779,  5.29396284,\n",
        "        5.29396284,  5.29396284,  2.6485885 ,  3.27149407,  2.28324849,\n",
        "        3.04285397,  2.22541396,  2.37483864,  2.04647176,  1.71384365,\n",
        "        2.46725197,  4.49258322,  4.08838779,  5.29396284,  5.29396284,\n",
        "        5.29396284,  2.6485885 ,  1.14932122,  2.09498194,  1.75965809,\n",
        "        1.14932122,  2.10842754,  2.49518534,  1.69085693,  1.512067  ,\n",
        "        1.08028477,  1.78120139,  0.91987539,  1.08706622,  1.2936678 ,\n",
        "        2.41882443,  1.41034709,  0.73662175,  1.61340265,  0.70862809,\n",
        "        0.83190123,  0.95672809,  1.0326104 ,  2.29589873,  2.5022368 ,\n",
        "        1.63636364,  3.18614952,  3.33132316,  3.00288808,  2.49518534,\n",
        "        3.33132316,  1.40987572,  1.92103291,  1.1451423 ,  0.76798663,\n",
        "        3.91569027,  1.08168384,  2.51644768,  1.59262524,  0.9548621 ,\n",
        "        1.07683914,  1.78145892,  1.94661731,  2.11188169,  2.59750815,\n",
        "        2.09498194,  1.1489177 ,  2.28873936,  1.10729494,  1.94661731,\n",
        "        3.01114368,  1.18082716,  4.04780783,  0.75964705,  1.59262524,\n",
        "        1.41034709,  1.19460428,  1.80478228,  2.32895012,  2.4631096 ,\n",
        "        2.27968526,  2.8664349 ,  2.75416624,  2.8288939 ,  2.49791941,\n",
        "        1.63636364,  0.92445258,  1.76731054,  0.95343643,  0.92445258,\n",
        "        1.47419595,  1.44437895,  1.43501656,  1.60682258,  1.13555551,\n",
        "        0.71972944,  1.03917243,  0.64211652,  1.94907455,  2.04629334,\n",
        "        2.63633721,  2.4944051 ,  2.20098912,  0.95914641,  1.43536638,\n",
        "        1.97992476,  1.1451423 ,  0.84986015,  1.42628837,  1.29389578,\n",
        "        1.23142214,  1.70572458,  1.29503659,  0.64211652,  4.49258322,\n",
        "        4.08838779,  5.29396284,  5.29396284,  5.29396284,  2.6485885 ,\n",
        "        1.52728289,  2.39102038,  2.4850591 ,  2.61231262,  2.7786031 ,\n",
        "        2.19146441,  0.99994457,  0.9548621 ,  0.84704054,  1.07664772,\n",
        "        2.92597609,  2.61231262,  3.13167233,  2.8563869 ,  3.40336261,\n",
        "        2.79505603,  3.13167233,  3.4587451 ,  2.40124007,  2.36816454,\n",
        "        1.14248359,  0.8401917 ,  2.7786031 ,  2.11391764,  2.0621636 ,\n",
        "        1.71606091,  2.09405   ,  2.09404424,  1.09854575,  2.09404424,\n",
        "        2.05221642,  3.4578504 ,  3.01114368,  2.8563869 ,  3.4587451 ,\n",
        "        2.32163348,  2.40124007,  2.11391764,  2.18803368,  1.61139466,\n",
        "        1.24455827,  0.95432045,  1.27139861,  0.72319834,  1.52399221,\n",
        "        1.67141513,  1.97208689,  1.36448518,  1.89224046,  1.64359209,\n",
        "        2.36816454,  1.59716839,  1.82084051,  1.59716839,  1.19218898,\n",
        "        2.21563771,  1.26407364,  1.86206295,  1.0326104 ,  1.8312895 ,\n",
        "        1.1489177 ,  1.09854575,  1.57574544,  1.13555551,  1.85072782,\n",
        "        3.05770206,  3.64212902,  1.76731054,  1.19218898,  2.3025303 ,\n",
        "        2.04785877,  2.6485885 ,  2.6485885 ,  2.6485885 ,  2.6485885 ,\n",
        "        0.88124374,  1.70880978,  1.29503659,  0.83415742,  1.43680718,\n",
        "        1.53558308,  1.97208689])"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Now I'll look at the descriptions for the 5 highest dot products."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted_scores = np.sort(dot_products)\n",
      "sorted_scores = sorted_scores[::-1]\n",
      "for i in range(5):\n",
      "    print('Highest Score Pair ' + str(i + 1))\n",
      "    print('--------------------------')\n",
      "    score = sorted_scores[2*i]\n",
      "    index = np.where(dot_products == score)\n",
      "    company_1 = extremes[0][index[0][0]]\n",
      "    company_2 = extremes[1][index[0][0]]\n",
      "    \n",
      "    print(\"Company 1: {}\\nCompany 2: {}\\n\".format(company_list.iloc[company_1][0], company_list.iloc[company_2][0]))\n",
      "\n",
      "    print(\"Company 1 Description 1:\\n{}\\n\".format(company_list.iloc[company_1][5]))\n",
      "    print(\"Company 2 Description 1:\\n{}\".format(company_list.iloc[company_2][5]))\n",
      "\n",
      "    print('\\n')\n",
      "    print(\"Company 1 Description 2:\\n{}\\n\".format(company_list.iloc[company_1][6]))\n",
      "    print(\"Company 2 Description 2:\\n{}\".format(company_list.iloc[company_2][6]))\n",
      "    print('\\n\\n')"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Highest Score Pair 1\n",
        "--------------------------\n",
        "Company 1: axstream.io\n",
        "Company 2: bold.co\n",
        "\n",
        "Company 1 Description 1:\n",
        "The company is currently operating in stealth mode.\n",
        "\n",
        "Company 2 Description 1:\n",
        "The company is currently operating in stealth mode.\n",
        "\n",
        "\n",
        "Company 1 Description 2:\n",
        "Other Business Products and Services\n",
        "\n",
        "Company 2 Description 2:\n",
        "Other Business Products and Services\n",
        "\n",
        "\n",
        "\n",
        "Highest Score Pair 2\n",
        "--------------------------\n",
        "Company 1: axstream.io\n",
        "Company 2: bold.co\n",
        "\n",
        "Company 1 Description 1:\n",
        "The company is currently operating in stealth mode.\n",
        "\n",
        "Company 2 Description 1:\n",
        "The company is currently operating in stealth mode.\n",
        "\n",
        "\n",
        "Company 1 Description 2:\n",
        "Other Business Products and Services\n",
        "\n",
        "Company 2 Description 2:\n",
        "Other Business Products and Services\n",
        "\n",
        "\n",
        "\n",
        "Highest Score Pair 3\n",
        "--------------------------\n",
        "Company 1: axstream.io\n",
        "Company 2: bold.co\n",
        "\n",
        "Company 1 Description 1:\n",
        "The company is currently operating in stealth mode.\n",
        "\n",
        "Company 2 Description 1:\n",
        "The company is currently operating in stealth mode.\n",
        "\n",
        "\n",
        "Company 1 Description 2:\n",
        "Other Business Products and Services\n",
        "\n",
        "Company 2 Description 2:\n",
        "Other Business Products and Services\n",
        "\n",
        "\n",
        "\n",
        "Highest Score Pair 4\n",
        "--------------------------\n",
        "Company 1: axstream.io\n",
        "Company 2: bold.co\n",
        "\n",
        "Company 1 Description 1:\n",
        "The company is currently operating in stealth mode.\n",
        "\n",
        "Company 2 Description 1:\n",
        "The company is currently operating in stealth mode.\n",
        "\n",
        "\n",
        "Company 1 Description 2:\n",
        "Other Business Products and Services\n",
        "\n",
        "Company 2 Description 2:\n",
        "Other Business Products and Services\n",
        "\n",
        "\n",
        "\n",
        "Highest Score Pair 5\n",
        "--------------------------\n",
        "Company 1: axstream.io\n",
        "Company 2: bold.co\n",
        "\n",
        "Company 1 Description 1:\n",
        "The company is currently operating in stealth mode.\n",
        "\n",
        "Company 2 Description 1:\n",
        "The company is currently operating in stealth mode.\n",
        "\n",
        "\n",
        "Company 1 Description 2:\n",
        "Other Business Products and Services\n",
        "\n",
        "Company 2 Description 2:\n",
        "Other Business Products and Services\n",
        "\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Now let's look at the 5 lowest dot products out of the pairs with the highest similarities."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted_scores = np.sort(dot_products)\n",
      "for i in range(5):\n",
      "    print('Lowest Score Pair ' + str(i + 1))\n",
      "    print('--------------------------')\n",
      "    score = sorted_scores[2*i]\n",
      "    index = np.where(dot_products == score)\n",
      "    company_1 = extremes[0][index[0][0]]\n",
      "    company_2 = extremes[1][index[0][0]]\n",
      "    \n",
      "    print(\"Company 1: {}\\nCompany 2: {}\\n\".format(company_list.iloc[company_1][0], company_list.iloc[company_2][0]))\n",
      "\n",
      "    print(\"Company 1 Description 1:\\n{}\\n\".format(company_list.iloc[company_1][5]))\n",
      "    print(\"Company 2 Description 1:\\n{}\".format(company_list.iloc[company_2][5]))\n",
      "\n",
      "    print('\\n')\n",
      "    print(\"Company 1 Description 2:\\n{}\\n\".format(company_list.iloc[company_1][6]))\n",
      "    print(\"Company 2 Description 2:\\n{}\".format(company_list.iloc[company_2][6]))\n",
      "    print('\\n\\n')"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Lowest Score Pair 1\n",
        "--------------------------\n",
        "Company 1: bythebridge.co.uk\n",
        "Company 2: cambiangroup.com\n",
        "\n",
        "Company 1 Description 1:\n",
        "Provider of foster care services. The company provides long-term specialist care, residential education, clinical and therapeutic inputs for children and adults.\n",
        "\n",
        "Company 2 Description 1:\n",
        "Provider of behavioral health services intended to offer psychiatric rehabilitation for patients with enduring mental health needs. The company's behavioral health services offer long-term specialist care, residential education, clinical and therapeutic inputs, enabling children and adults to get help for Autism, Asperger's Syndrome, severe learning disabilities, challenging behavior and complex needs.\n",
        "\n",
        "\n",
        "Company 1 Description 2:\n",
        "Other Healthcare Services\n",
        "\n",
        "Company 2 Description 2:\n",
        "Elder and Disabled Care\n",
        "\n",
        "\n",
        "\n",
        "Lowest Score Pair 2\n",
        "--------------------------\n",
        "Company 1: andrewalliance.com\n",
        "Company 2: bionic-robotics.de\n",
        "\n",
        "Company 1 Description 1:\n",
        "Developer of robots. The company develops a co-worker robot that makes laboratory operations more efficient.\n",
        "\n",
        "Company 2 Description 1:\n",
        "Developer of lightweight construction robots. The company develops a robot which is used for industrial automation, especially for inspection and co-worker applications.\n",
        "\n",
        "\n",
        "Company 1 Description 2:\n",
        "Electrical Equipment\n",
        "\n",
        "Company 2 Description 2:\n",
        "Electrical Equipment\n",
        "\n",
        "\n",
        "\n",
        "Lowest Score Pair 3\n",
        "--------------------------\n",
        "Company 1: amkor.com\n",
        "Company 2: apmcn.com\n",
        "\n",
        "Company 1 Description 1:\n",
        "Provider of semiconductor packaging and testing services in Korea.\n",
        "\n",
        "Company 2 Description 1:\n",
        "Provider of semiconductor packaging and testing services. The company develops and supplies wide range of power semiconductors.\n",
        "\n",
        "\n",
        "Company 1 Description 2:\n",
        "Other Semiconductors\n",
        "\n",
        "Company 2 Description 2:\n",
        "Application Specific Semiconductors\n",
        "\n",
        "\n",
        "\n",
        "Lowest Score Pair 4\n",
        "--------------------------\n",
        "Company 1: bladonjets.com\n",
        "Company 2: bowmanpower.com\n",
        "\n",
        "Company 1 Description 1:\n",
        "Manufacturer of micro gas-turbine engines. The company develops its engines for electric vehicles and other power-generation applications.\n",
        "\n",
        "Company 2 Description 1:\n",
        "Developer of micro turbine equipment for diesel engine. The company develops electricity generation technology for standard diesel and gas fueled engines.\n",
        "\n",
        "\n",
        "Company 1 Description 2:\n",
        "Alternative Energy Equipment\n",
        "\n",
        "Company 2 Description 2:\n",
        "Industrial Supplies and Parts\n",
        "\n",
        "\n",
        "\n",
        "Lowest Score Pair 5\n",
        "--------------------------\n",
        "Company 1: apnexmedical.com\n",
        "Company 2: apnicure.com\n",
        "\n",
        "Company 1 Description 1:\n",
        "Developer of implantable technology to treat obstructive sleep apnea. The company is developing an active implantable medical device for the treatment of moderate-to-severe obstructive sleep apnea (OSA).\n",
        "\n",
        "Company 2 Description 1:\n",
        "Developer of home-use device for the treatment of obstructive sleep apnea (OSA) in adults. The company's winx system uses a proprietary platform technology called Oral Pressure Therapy (OPT) to treat OSA.\n",
        "\n",
        "\n",
        "Company 1 Description 2:\n",
        "Surgical Devices\n",
        "\n",
        "Company 2 Description 2:\n",
        "Therapeutic Devices\n",
        "\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "The top 5 pairs were all in stealth-mode, so functionally they're the same as far as we're concerned.  However, the bottom 5 pairs are especially promising; most of these pairs companies have similar sounding descriptions, yet are aimed at different markets in an ever so subtle way.  This seems great."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Connected Components"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Now I'll check how connected the graph is."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import networkx as nx\n",
      "G=nx.Graph()\n",
      "G.add_nodes_from(range(n_companies))\n",
      "for i in range(n_companies):\n",
      "    for k in range(i+1, n_companies):\n",
      "        if company_graph[i][k] != 0:\n",
      "            G.add_edge(i,k)\n",
      "            G[i][k]['weight'] = company_graph[i][k]\n",
      "\n",
      "print(\"Is the graph fully connected?: {}\".format(nx.is_connected(G)))\n",
      "print(\"Number of nodes in the graph: {}\".format(nx.number_of_nodes(G)))\n",
      "print(\"Number of connected components: {}\".format(nx.number_connected_components(G)))"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is the graph fully connected?: False\n",
        "Number of nodes in the graph: 10000\n",
        "Number of connected components: 636"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "    The graph isn't connected, and has many connected components.  Let's see how nodes are distributed across these components."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "connected_components = sorted(nx.connected_components(G), key = len, reverse = True)\n",
      "n_components = len(connected_components)\n",
      "elements_per_component = np.empty(n_components, dtype = int)\n",
      "for i in range(n_components):\n",
      "    elements_per_component[i] = len(connected_components[i])\n",
      "elements_per_component\n"
     ],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "array([9348,    3,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
        "          2,    2,    2,    2,    2,    2,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1])"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "    The majority of nodes are in one connected component, and the rest of the connected components are almost exclusively single nodes with no edges, with the exception of a few lone pairs/lone triumvirates.  Thus, while the graph isn't connected, for our intents/purposes we can treat it like it is (nodes with no edges won't provide any value in determining similarity), allowing the dot product/shared neighbors approach to potentially work."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "Conclusion"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "source": [
      "    Taking dot products seems to provide for some level of correction (albeit based on 1 pair that was marginally corrected by the low dot-product), even in the case of the pairs with the highest textual similarity.  It thus seems like a good denoising technique to use on the real graph."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {
      "deletable": true,
      "editable": true
     },
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}