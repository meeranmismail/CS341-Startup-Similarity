{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "name": "",
  "signature": "sha256:e23c87512f5e9ce1da91c680da6a4d11b8697050a246003117f9ecf69af39417"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below is some starter code to get the IDF vector, and view it so we can start making calculations and generating the graph"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# Read in the IDF vector\n",
      "idf_vector = pd.read_csv(\"~/CS341/data/training_idf_vector.csv\" ,header=None, names=['IDF'], index_col=0, encoding = \"ISO-8859-1\")\n",
      "idf_vector"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>IDF</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>cranberries</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>site\u00c3\u00ads</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>maintainable</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>fermented</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>raspberry</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>pomegranate</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>juice</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>chinesespeaking</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>loop</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>affairs</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>towels</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>carpets</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>quilts</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>cloth</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>bedding</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>board</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>commercialuse</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>member</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>analysing</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>executing</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>temporary</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>confined</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>scaffolding</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>structural</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>321</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>eworkshops</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>micronized</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>continuing</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>econference</th>\n",
        "      <td>7.313554</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>operator</th>\n",
        "      <td>2.438356</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>enables</th>\n",
        "      <td>2.368346</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mobile</th>\n",
        "      <td>2.350709</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>on</th>\n",
        "      <td>2.350709</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>software</th>\n",
        "      <td>2.340274</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>companys</th>\n",
        "      <td>2.323121</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>which</th>\n",
        "      <td>2.216741</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>application</th>\n",
        "      <td>2.207608</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>users</th>\n",
        "      <td>2.087807</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>develops</th>\n",
        "      <td>2.082445</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>their</th>\n",
        "      <td>2.077112</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>with</th>\n",
        "      <td>2.025287</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>online</th>\n",
        "      <td>1.764478</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>services</th>\n",
        "      <td>1.724434</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>provides</th>\n",
        "      <td>1.551502</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>offers</th>\n",
        "      <td>1.540556</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>that</th>\n",
        "      <td>1.537451</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>an</th>\n",
        "      <td>1.511435</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>NaN</th>\n",
        "      <td>1.506914</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>developer</th>\n",
        "      <td>1.490508</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>in</th>\n",
        "      <td>1.433021</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>platform</th>\n",
        "      <td>1.299839</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>for</th>\n",
        "      <td>0.965289</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>provider</th>\n",
        "      <td>0.873405</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>to</th>\n",
        "      <td>0.842754</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>a</th>\n",
        "      <td>0.827393</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>company</th>\n",
        "      <td>0.384037</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>and</th>\n",
        "      <td>0.376240</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>of</th>\n",
        "      <td>0.255656</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <td>0.255656</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>7602 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "                      IDF\n",
        "3                7.313554\n",
        "cranberries      7.313554\n",
        "site\u00c3\u00ads          7.313554\n",
        "maintainable     7.313554\n",
        "fermented        7.313554\n",
        "raspberry        7.313554\n",
        "pomegranate      7.313554\n",
        "juice            7.313554\n",
        "chinesespeaking  7.313554\n",
        "loop             7.313554\n",
        "affairs          7.313554\n",
        "towels           7.313554\n",
        "carpets          7.313554\n",
        "quilts           7.313554\n",
        "cloth            7.313554\n",
        "bedding          7.313554\n",
        "board            7.313554\n",
        "commercialuse    7.313554\n",
        "member           7.313554\n",
        "analysing        7.313554\n",
        "executing        7.313554\n",
        "temporary        7.313554\n",
        "confined         7.313554\n",
        "scaffolding      7.313554\n",
        "structural       7.313554\n",
        "321              7.313554\n",
        "eworkshops       7.313554\n",
        "micronized       7.313554\n",
        "continuing       7.313554\n",
        "econference      7.313554\n",
        "...                   ...\n",
        "operator         2.438356\n",
        "enables          2.368346\n",
        "mobile           2.350709\n",
        "on               2.350709\n",
        "software         2.340274\n",
        "companys         2.323121\n",
        "which            2.216741\n",
        "application      2.207608\n",
        "users            2.087807\n",
        "develops         2.082445\n",
        "their            2.077112\n",
        "with             2.025287\n",
        "online           1.764478\n",
        "services         1.724434\n",
        "provides         1.551502\n",
        "offers           1.540556\n",
        "that             1.537451\n",
        "an               1.511435\n",
        "NaN              1.506914\n",
        "developer        1.490508\n",
        "in               1.433021\n",
        "platform         1.299839\n",
        "for              0.965289\n",
        "provider         0.873405\n",
        "to               0.842754\n",
        "a                0.827393\n",
        "company          0.384037\n",
        "and              0.376240\n",
        "of               0.255656\n",
        "the              0.255656\n",
        "\n",
        "[7602 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The idf vector can be converted to a numpy array for linear algebra calculatons via these command:\n",
      "\n",
      "# Get the idf values in a column vector\n",
      "idf_values = list(idf_vector.values)\n",
      "\n",
      "# Get the words in a column vector. The initial order mathes the values in the idf_values_array\n",
      "idf_words = list(idf_vector.index.values)\n",
      "# Perform a reshape on the words array to get it in a better format\n",
      "\n",
      "idf_set = set(idf_words)\n",
      "idf_map = dict(zip(idf_words, idf_values))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Creating the Graph"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The next step will be to create an adjacency matrix to store all these values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import pandas as pd\n",
      "\n",
      "company_list = pd.read_csv('~/CS341/data/category_training_labeled_fixed.csv', encoding = \"ISO-8859-1\")\n",
      "n_companies = shape(company_list)[0]\n",
      "company_graph = np.empty((n_companies,n_companies))\n",
      "company_graph[:] = -1\n",
      "company_graph"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([[-1., -1., -1., ..., -1., -1., -1.],\n",
        "       [-1., -1., -1., ..., -1., -1., -1.],\n",
        "       [-1., -1., -1., ..., -1., -1., -1.],\n",
        "       ..., \n",
        "       [-1., -1., -1., ..., -1., -1., -1.],\n",
        "       [-1., -1., -1., ..., -1., -1., -1.],\n",
        "       [-1., -1., -1., ..., -1., -1., -1.]])"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we'll go through each word and see which companies have that word.  We'll go through the top 1000 idf words, find the companies with those words, and then compare them to create the edge weight in the graph.  First, the following function creates a set of words out of the description"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import string\n",
      "import nltk\n",
      "nltk.download('punkt')\n",
      "\n",
      "#Gets the words out of the labeled descriptions\n",
      "def get_words(df):\n",
      "    punctuation = '[^\\w\\s]'\n",
      "    txt = df.str.lower().str.replace(punctuation, ' ').str.cat(sep=' ')\n",
      "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
      "    words = nltk.tokenize.word_tokenize(txt)\n",
      "    return set(words) - stopwords\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[nltk_data] Downloading package punkt to\n",
        "[nltk_data]     /Users/Meeranster/nltk_data...\n",
        "[nltk_data]   Package punkt is already up-to-date!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we create a company_words_list, i.e. each company is associated with a set of words."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "company_words_list = [set()]*len(company_list)\n",
      "for i in range(len(company_list)):\n",
      "    start_index = 5\n",
      "    end_index = 7\n",
      "    company_words = get_words(company_list.iloc[i,start_index:end_index])\n",
      "    company_words_list[i] = company_words\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This function goes through the list of companies and sees if a given word is in the description for each of the companies, returning a set of company indices with that word."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#given a target word and a pandas data frame of companies, returns a list of companies whose descriptions contain the target word\n",
      "def get_companies(target_word, company_words_list):\n",
      "    candidate_set = set()\n",
      "    for i in range(len(company_words_list)):\n",
      "        company_description = company_words_list[i]\n",
      "        if target_word in company_description:\n",
      "            candidate_set.add(i)\n",
      "    return list(candidate_set)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This function takes a candidate pair, and computes their weighted similarity by finding Jaccard similarity and then weighing it by the idf of the words."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_similarity(company_index_1, company_index_2, company_words_list, idf_set, idf_map):\n",
      "    company_1 = company_words_list[company_index_1]\n",
      "    company_2 = company_words_list[company_index_2]\n",
      "    intersection = company_1 & company_2\n",
      "    union = company_1 | company_2\n",
      "    if len(union) == 0:\n",
      "        return 0\n",
      "    intersection_score = 0.0\n",
      "    union_score = 0.0\n",
      "    for word in union:\n",
      "        if word in idf_set:\n",
      "            word_score = idf_map[word][0]\n",
      "            union_score += word_score\n",
      "            if word in intersection:\n",
      "                intersection_score += word_score\n",
      "                \n",
      "    return intersection_score/union_score\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we go through and construct the 3000x3000 adjacency matrix."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_updated_elements = 0\n",
      "n_companies = len(company_list)\n",
      "cutoff = 0.1\n",
      "for i in range(n_companies):\n",
      "    for k in range((i+1), n_companies):\n",
      "        edge_weight = get_similarity(i, k, company_words_list, idf_set, idf_map)\n",
      "        if edge_weight >= cutoff:\n",
      "            company_graph[i][k] = edge_weight\n",
      "            company_graph[k][i] = edge_weight\n",
      "        \n",
      "#removing -1's and ensuring 1's along the diagonal\n",
      "\n",
      "np.fill_diagonal(company_graph, 1)\n",
      "company_graph[company_graph < 0] = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here I test different cutoffs for similarity scores to count as edges."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cutoff_sparsity = np.zeros(20)\n",
      "#cutoff_sparsity[i] gives the sparsity of the graph if similarity threshold is (i+1)*0.01\n",
      "n_possible_edges = float(size(company_graph) - n_companies)\n",
      "for i in range(20):\n",
      "    cutoff_sparsity[i] = (size(company_graph[company_graph > (i+1)*0.01]) - n_companies)/n_possible_edges\n",
      "print(cutoff_sparsity)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  3.93993331e-01   2.30383239e-01   1.28225631e-01   7.06144270e-02\n",
        "   3.94916083e-02   2.25310659e-02   1.30741358e-02   7.82483050e-03\n",
        "   4.76558853e-03   2.96654440e-03   1.89818828e-03   1.22996554e-03\n",
        "   8.15827498e-04   5.48182728e-04   3.81015894e-04   2.66310993e-04\n",
        "   1.89841058e-04   1.33600089e-04   9.75880849e-05   7.42469712e-05]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Dot Product Heuristic"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now I'm going to perform a very simple heuristic to see how well the dot products predict similarity by seeing how they function on the company pairs with the highest textual similarity scores."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mask = ~np.eye(company_graph.shape[0], dtype = bool)\n",
      "extremes = np.where((mask) & (company_graph > 0.3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dot_products = np.zeros(len(extremes[0]))\n",
      "for i in range(len(dot_products)):\n",
      "    company_1 = extremes[0][i]\n",
      "    company_2 = extremes[1][i]\n",
      "    dot_products[i] = company_graph[company_1].dot(company_graph[company_2])\n",
      "dot_products"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 150,
       "text": [
        "array([ 0.69330862,  0.90417218,  1.71260869,  1.61657171,  1.29913586,\n",
        "        1.2257629 ,  0.95838728,  0.95838728,  1.05905751,  0.84131409,\n",
        "        0.8595902 ,  1.05905751,  0.8595902 ,  0.94622351,  0.81868064,\n",
        "        1.2257629 ,  0.90417218,  0.85326372,  0.84131409,  1.71260869,\n",
        "        1.19521275,  0.94622351,  0.76450024,  0.81868064,  0.75469454,\n",
        "        1.08860499,  0.69330862,  0.75469454,  1.26190621,  1.61657171,\n",
        "        0.76450024,  1.08860499,  1.26190621,  0.85326372,  1.29913586,\n",
        "        1.19521275])"
       ]
      }
     ],
     "prompt_number": 150
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now I'll look at the descriptions for the 5 highest dot products."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted_scores = sort(dot_products)\n",
      "sorted_scores = sorted_scores[::-1]\n",
      "for i in range(5):\n",
      "    print('Description ' + str(i + 1))\n",
      "    score = sorted_scores[2*i]\n",
      "    index = np.where(dot_products == score)\n",
      "    company_1 = extremes[0][index[0][0]]\n",
      "    company_2 = extremes[1][index[0][0]]\n",
      "    print(company_list.ix[company_1][0] + ' and ' + company_list.ix[company_2][0])\n",
      "    print(company_list.ix[company_1][5])\n",
      "    print(company_list.ix[company_2][5])\n",
      "    print('\\n')\n",
      "    print(company_list.ix[company_1][6])\n",
      "    print(company_list.ix[company_2][6])\n",
      "    print('\\n\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Description 1\n",
        "ffan.com and skoov.com"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nan\n",
        "nan\n",
        "\n",
        "\n",
        "ffan.com, an e-commerce website jointly established by Tencent, Baidu and Wanda Group\n",
        "Skoov.com is an e-commerce product search engine,\n",
        "\n",
        "\n",
        "\n",
        "Description 2\n",
        "ffan.com and channelape.com\n",
        "nan\n",
        "nan\n",
        "\n",
        "\n",
        "ffan.com, an e-commerce website jointly established by Tencent, Baidu and Wanda Group\n",
        "Omni-channel E-commerce Management\n",
        "\n",
        "\n",
        "\n",
        "Description 3\n",
        "cincinnatifederal.com and csb-bk.com\n",
        "Operator of a bank holding company. The company through its subsidiaries provides banking and banking and financial services to individual and corporate customers.\n",
        "Operator of a bank holding company. The company through its subsidiary provides personal and commercial banking services to its customers.\n",
        "\n",
        "\n",
        "nan\n",
        "nan\n",
        "\n",
        "\n",
        "\n",
        "Description 4\n",
        "pocketlistings.net and groffr.com\n",
        "nan\n",
        "nan\n",
        "\n",
        "\n",
        "Off Market Real Estate Network\n",
        "groffr.com is real estate based company.\n",
        "\n",
        "\n",
        "\n",
        "Description 5\n",
        "ambyant.me and cloudspottertechnologies.com\n",
        "Provider of a private photo sharing application. The company offers a mobile application allowing users to post their photos, create albums and privately share photos with other users.\n",
        "Provider of an automatic photo sharing platform. The company offers a web-based, automated photo sharing platform allowing users to privately share photos in the cloud.\n",
        "\n",
        "\n",
        "nan\n",
        "nan\n",
        "\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's look at the 5 lowest dot products out of the pairs with the highest similarities."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted_scores = sort(dot_products)\n",
      "for i in range(5):\n",
      "    print('Description ' + str(i + 1))\n",
      "    score = sorted_scores[2*i]\n",
      "    index = np.where(dot_products == score)\n",
      "    company_1 = extremes[0][index[0][0]]\n",
      "    company_2 = extremes[1][index[0][0]]\n",
      "    print(company_graph[company_1][company_2])\n",
      "    print(company_graph[company_1].dot(company_graph[company_2]))\n",
      "    print(company_list.ix[company_1][0] + ' and ' + company_list.ix[company_2][0])\n",
      "    print(company_list.ix[company_1][5])\n",
      "    print(company_list.ix[company_2][5])\n",
      "    print('\\n')\n",
      "    print(company_list.ix[company_1][6])\n",
      "    print(company_list.ix[company_2][6])\n",
      "    print('\\n\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Description 1\n",
        "0.325178387878\n",
        "0.693308620593\n",
        "aftercollege.com and graduateland.com\n",
        "Operator of an online career network providing employment services for college students and graduates. The company connects college students, alumni and employers through faculty and career networks at colleges and universities.\n",
        "Provider of an online recruitment platform. The company's software creates a network that connects students or graduates, employers and universities via its job portal.\n",
        "\n",
        "\n",
        "AfterCollege is a career network connecting college students and recent graduates with employers.\n",
        "Graduateland offers a career network for students and recent graduates, enabling them to discover job opportunities.\n",
        "\n",
        "\n",
        "\n",
        "Description 2\n",
        "0.301157430116\n",
        "0.754694541929\n",
        "actslike.com and captchaad.com\n",
        "nan\n",
        "Provider of online video advertising services. The company provides interactive video advertisement services which connects advertisers and publishers with consumers through websites, blogs, social platforms and mobile applications.\n",
        "\n",
        "\n",
        "Actslike is an advertisement platform that provides online solutions for content publishers, advertisers, and agencies.\n",
        "CaptchaAd provides online video advertising solutions.\n",
        "\n",
        "\n",
        "\n",
        "Description 3\n",
        "0.302917938166\n",
        "0.764500241507\n",
        "canarddrones.com and ideaforge.co.in\n",
        "Manufacturer of drones and unmanned aerial vehicles. The company designs and develops automated calibration and verification of approaching lighting systems using unmanned aerial vehicles and drones.\n",
        "Developer of drones. The company develops and manufactures autonomous man-portable Unmanned Aerial Vehicles (UAVs).\n",
        "\n",
        "\n",
        "CANARD allows fast calibration of NavAids by using fully automated, unmanned UAVs (drones).\n",
        "ideaForge is an Indian company engaged in the development of unmanned aerial systems.\n",
        "\n",
        "\n",
        "\n",
        "Description 4\n",
        "0.334364562663\n",
        "0.818680638956\n",
        "honleylaw.co.uk and gcmochrie.com\n",
        "Provider of legal services. The company specializes in family law, employment law, property law, wills, probate, powers of attorney, commercial law, notary services and conveyancing solicitors in the United Kingdom.\n",
        "Provider of legal services. The practice is engaged in providing legal services to private clients in the fields of residential property conveyancing, wills, lasting powers of attorney and court of protection and family law.\n",
        "\n",
        "\n",
        "nan\n",
        "nan\n",
        "\n",
        "\n",
        "\n",
        "Description 5\n",
        "0.351286670386\n",
        "0.84131408781\n",
        "homepage.com and jupviec.vn\n",
        "nan\n",
        "nan\n",
        "\n",
        "\n",
        "HomePage.com is the leading Application Service Provider.\n",
        "JupViec.vn is a leading housekeeping service in Vietnam\n",
        "\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Both the top 5 and bottom 5 pairs had very high similarity for the most part, but perhaps that's just because I looked at such an extreme top end of textual similarity scores.  However, even here, the de-noising via dot product seems to work, especially in the case of homepage.com and jupviec.vn, which aren't as similar as their high textual similarity would seem to suggest."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Connected Components"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now I'll check how connected the graph is."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import networkx as nx\n",
      "G=nx.Graph()\n",
      "G.add_nodes_from(company_list.index.values)\n",
      "for i in range(n_companies):\n",
      "    for k in range(i+1, n_companies):\n",
      "        if company_graph[i][k] != 0:\n",
      "            G.add_edge(i,k)\n",
      "            G[i][k]['weight'] = company_graph[i][k]\n",
      "\n",
      "print(nx.is_connected(G))\n",
      "print(nx.number_of_nodes(G))\n",
      "print(nx.number_connected_components(G))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "False\n",
        "3000\n",
        "492\n"
       ]
      }
     ],
     "prompt_number": 164
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The graph isn't connected, and has many connected components.  Let's see how nodes are distributed across these components."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "connected_components = sorted(nx.connected_components(G), key = len, reverse = True)\n",
      "n_components = len(connected_components)\n",
      "elements_per_component = np.empty(n_components, dtype = int)\n",
      "for i in range(n_components):\n",
      "    elements_per_component[i] = len(connected_components[i])\n",
      "elements_per_component\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 181,
       "text": [
        "array([2499,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "          1,    1,    1,    1,    1,    1,    1,    1])"
       ]
      }
     ],
     "prompt_number": 181
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The majority of nodes are in one connected component, and the rest of the connected components are almost exclusively single nodes with no edges, with the exception of a few lone pairs.  Thus, while the graph isn't connected, for our intents/purposes we can treat it like it is (nodes with no edges won't provide any value in determining similarity), allowing the dot product/shared neighbors approach to potentially work."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Conclusion"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Taking dot products seems to provide for some level of correction (albeit based on 1 pair that was marginally corrected by the low dot-product), even in the case of the pairs with the highest textual similarity.  It thus seems like a good denoising technique to use on the real graph."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}